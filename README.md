# Comparison between Ray and Spark for big data analysis and ML

>> Python 2: Ray, Spark

>> Team ID: 5

This project explores a comparative study of Ray and Apache Spark, two leading Python-based frameworks for scalable big data processing and machine learning tasks. The objective is to evaluate their performance, scalability, and suitability for handling large-scale datasets that exceed main memory capacity, involving millions or billions of records. Both systems will be installed and configured on local or Okeanos-based resources, with a shared dataset loaded into each framework for consistency. A series of Python scripts will benchmark their capabilities across a variety of scenarios, including common ETL workflows and machine learning operations such as prediction, clustering, and graph analysis. By varying the number of nodes, input data size, and data types, the study aims to derive meaningful insights into the strengths and limitations of each framework, providing a comprehensive analysis of their scalability and efficiency for real-world applications.

## Part 1: Install and setup

Installation and setup instructions for VMs, Hadoop, Ray and Spark on local or Okeanos-based resources, and the [assignment](https://github.com/ntua-el20439/Big-Data-HDFS-Ray-vs-Spark/blob/main/documentation/ASSIGNMENT.md) can be found in the [documentation](https://github.com/ntua-el20439/Big-Data-HDFS-Ray-vs-Spark/blob/main/documentation/README.md) folder.

## Part 2: Data gathering

More info at the [data](https://github.com/ntua-el20439/Big-Data-HDFS-Ray-vs-Spark/blob/main/data/README.md) folder.

## Part 3: Analysis

More info at the [analysis](https://github.com/ntua-el20439/Big-Data-HDFS-Ray-vs-Spark/blob/main/analysis/README.md) folder.

## Part 4: Report

More info at the [report](https://github.com/ntua-el20439/Big-Data-HDFS-Ray-vs-Spark/blob/main/report/README.md) folder.